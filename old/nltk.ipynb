{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import casual_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv('review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = review.copy().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus.reader.wordnet import NOUN, VERB, ADJ, ADV\n",
    "    \n",
    "    word, pos = x\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    if pos == 'NOUN':\n",
    "        return wordnet_lemmatizer.lemmatize(word, NOUN)\n",
    "    elif pos == 'VERB':\n",
    "        return wordnet_lemmatizer.lemmatize(word, VERB)\n",
    "    elif pos == 'ADJ':\n",
    "        return wordnet_lemmatizer.lemmatize(word, ADJ)\n",
    "    elif pos == 'ADV':\n",
    "        return wordnet_lemmatizer.lemmatize(word, ADV)\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase conversion\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda row: ' '.join([x for x in casual_tokenize(row) if x not in ENGLISH_STOP_WORDS]))\n",
    "\n",
    "## Expand contractions\n",
    "\n",
    "# Remove punctuations\n",
    "punct = r'[{}]'.format(string.punctuation)\n",
    "df['text'] = df['text'].str.replace(punct, '')\n",
    "\n",
    "# Remove digits\n",
    "digit = r'\\d+'\n",
    "df['text'] = df['text'].str.replace(digit, '')\n",
    "\n",
    "# Whitespace removal\n",
    "whitespace = r'\\s+'\n",
    "df['text'] = df['text'].str.replace(whitespace, ' ')\n",
    "\n",
    "# Strip trailing whitespace\n",
    "df['text'] = df['text'].str.strip()\n",
    "\n",
    "# Tag part of speech\n",
    "df['text'] = df['text'].apply(lambda x: pos_tag(word_tokenize(x), tagset='universal'))\n",
    "\n",
    "# Lemmatization\n",
    "df['text'] = df['text'].apply(lambda row: ' '.join([lemmatize(x) for x in row])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chevos chandler delicious ahwatukee different reason order chicken roll taco today tiny lil piece chicken basically roll deep fry tortilla yuck flavor order carne asada taco meat taste old like cook earlier just throw grill warm dissapointed',\n",
       " 'place dirty grimy twice customer service horrible',\n",
       " 'holy portion size lot bang buck service super fast love tempura avocado appetizer',\n",
       " 'flavor actually pretty good use eat menudo tortilla pleasant lemonade good flavor ask refill bring service prompt food table time really busy maybe help good experience',\n",
       " 'place great flavor server thing ask bring chip salsa begin meal great flavor bread menudo toast spread butter home flavor gladly recommend place star instead star coke zero expire gladly replace new question ask great service']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carlsbad truly favorite place valley usually opportunity lunch place hold special place heart real meal arizona lunch trip interview favorite place coworkers visit thing atmosphere fantastic inside outside great seat love welcome feel arrive staff decor outdoor seat area best ive youve sit outdoor bar pond truly miss food fantastic portion price blue corn enchilada favorites warn eat fan cheese live cheese love lunch special incredible definitely worth try dont know thats disappointed time roast chicken enchilada mushroom cream sauce say eat enjoy fantastic food amazingly personable staff great setting',\n",
       " 'abridge good food hotel restaurant feel head alexis friend good old carbs veggie run saturday night arrive little worried starch burgundy table decor lack patron think stiff uncomfortable hotel restaurant server friendly knowledgeable menu look fantastic soso price end primavera dish stay water drink food great bread devour pleasure end dont think patron staff amuse ordinary conversation friend like food good wont write list wouldnt surprise didnt welcome kind haha',\n",
       " 'fiesta burrito pretty close office month ago coworkers introduce time quick mexican place definitely worth price decent fairly extensive menu service fast downsides park limit cause issue time today seat limit fairly small joint non tomato fan mood guac doesnt leave choice option pretty plain limited time say definitely worth try area suggest carne asada burrito',\n",
       " 'ive twice average visit time evfn event star embarrassingly terrible service margarita time din lunch group unbelievable let just start salsa lovely surprisingly dark addictive salsa recall occasion inquire available home purchase yay non tomato base salsa additionally seafood enchilada die honestly just right size lunch salmon halibut shrimp delicious cheese tomato request green chile amaze flavor end crave rest day group completely satisfy meatloaf sandwich lunch special coworker look delicious dont really like meatloaf service kinda awkward lack word completely feel place little way work lunch spot occasion wont complain tell horrid experience',\n",
       " 'thats damn good bruschetta fan tomato persuasion know comfort lately bruschetta contain tomato postinos offer great alternative divine favorite far pistachio devour second fave roast red bell pepper mmmmmm okay need stop think breakfast crave food server super nice attentive felt like resort pamper brunch friend champagne honey cucumber lemonade concoction erupt like mt st helens champagne drink champion time promptly come towel clean table love country toast mouth water bit surprise tomato salad plate didnt list item menu meh easily push aside thing come tomato default garnish ate bit food consume entire champagne beverage sure surprising outdoor patio beautiful really tight fit pretty close cactus close comfort likely']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].tail().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.6/site-packages (from textblob) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stripe'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install textblob\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "# Lemmatize a word\n",
    "word = 'stripes'\n",
    "w = Word(word)\n",
    "w.lemmatize()\n",
    "#> stripe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The striped bat are hanging on their foot for best'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize a sentence\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "sent = TextBlob(sentence)\n",
    "\" \". join([w.lemmatize() for w in sent.words])\n",
    "#> 'The striped bat are hanging on their foot for best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The striped bat be hang on their foot for best'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to lemmatize each word with its POS tag\n",
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "# Lemmatize\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "lemmatize_with_postag(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter POS tag: e.g. VERB, JJ, NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find better lemmatizer: try spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
